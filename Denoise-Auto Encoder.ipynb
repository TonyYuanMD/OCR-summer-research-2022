{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image as ImagePIL\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(array):\n",
    "    \"\"\"\n",
    "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
    "    \"\"\"\n",
    "\n",
    "    array = array.astype(\"float32\") / 255.0\n",
    "    #array = np.reshape(array, (len(array), 28, 28, 1))\n",
    "    return array\n",
    "\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    images1 = array1[indices, :]\n",
    "    images2 = array2[indices, :]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1)\n",
    "        # plt.imshow(image1.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2)\n",
    "        # plt.imshow(image2.reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special need for google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do this one only when we need clean images\n",
    "def process_image(path):\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    #Increase contrast\n",
    "\n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "\n",
    "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    #Opencv denoise\n",
    "\n",
    "    dn = cv2.fastNlMeansDenoisingColored(enhanced_img,None,10,10,7,21)\n",
    "\n",
    "    cv2.imwrite('Clean_'+f, dn)\n",
    "\n",
    "    a = 1\n",
    "\n",
    "    return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clean images\n",
    "for f in train_img:\n",
    "    process_image( '/content/drive/MyDrive/OCR_summer/OCR_Dataset/'+ f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de51870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle trainning set\n",
    "os.chdir(\"/content/drive/MyDrive/OCR_summer/OCR_Dataset\")\n",
    "\n",
    "train_dir = \"/content/drive/MyDrive/OCR_summer/train\"\n",
    "Clean_train_dir = \"/content/drive/MyDrive/OCR_summer/train_cleaned\"\n",
    "test_img_dir = \"/content/drive/MyDrive/OCR_summer/OCR_Dataset/train_demo\"\n",
    "\n",
    "\n",
    "train_img = sorted(os.listdir(train_dir))\n",
    "Clean_train_img = sorted(os.listdir(Clean_train_dir))\n",
    "test_img =sorted(os.listdir(test_img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3def53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OCR training set\n",
    "train_dir = \"/content/drive/MyDrive/OCR_summer/OCR_Dataset/train\"\n",
    "Clean_train_dir = \"/content/drive/MyDrive/OCR_summer/OCR_Dataset/Clean_train\"\n",
    "test_img_dir = \"/content/drive/MyDrive/OCR_summer/OCR_Dataset/train_demo\"\n",
    "\n",
    "train_img = sorted(os.listdir(train_dir))\n",
    "Clean_train_img = sorted(os.listdir(Clean_train_dir))\n",
    "test_img =sorted(os.listdir(test_img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2388e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 540\n",
    "IMG_HEIGHT = 420\n",
    "\n",
    "# prepare function\n",
    "def sizedown_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = np.asarray(img, dtype=\"float32\")\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img/255.0\n",
    "    img = np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385844c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "train_cleaned = []\n",
    "test = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for f in train_img:\n",
    "    if i <= 75:\n",
    "       i = i+1\n",
    "       train.append(sizedown_image( train_dir + '/'+ f))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for f in Clean_train_img:\n",
    "    if i <= 75:\n",
    "      i=i+1\n",
    "      train_cleaned.append(sizedown_image(Clean_train_dir+'/' + f))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for f in test_img:\n",
    "    if i <= 75: \n",
    "      i=i+1\n",
    "      test.append(sizedown_image(test_img_dir + '/' + f))\n",
    "\n",
    "X_train = np.asarray(train)\n",
    "Y_train = np.asarray(train_cleaned)\n",
    "test = np.asarray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d367c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Websita encoder Part1\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "IMG_WIDTH = 540\n",
    "IMG_HEIGHT = 420\n",
    "\n",
    "input = layers.Input(shape=T(IMG_HEIGH, IMG_WIDTH, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba15040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Website encoder Part2\n",
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "history = autoencoder.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7daacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "model.load_weights('./model4/epochs80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check model outcome\n",
    "epoch_loss = history.history['loss']\n",
    "epoch_val_loss = history.history['val_loss']\n",
    "# epoch_mae = history.history['mae']\n",
    "# epoch_val_mae = history.history['val_mae']\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\n",
    "plt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\n",
    "plt.title('Evolution of loss on train & validation datasets over epochs')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')\n",
    "plt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')\n",
    "plt.title('Evolution of MAE on train & validation datasets over epochs')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92531237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "os.chdir('/content/drive/MyDrive/OCR_summer/OCR_Dataset') \n",
    "autoencoder.save_weights('./model5/epochs50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fe6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process single image under model\n",
    "figure = []\n",
    "figure.append(sizedown_image('/content/drive/MyDrive/OCR_summer/OCR_Dataset/train/IMG_0845.JPG'))\n",
    "\n",
    "\n",
    "figure = np.asarray(figure)\n",
    "\n",
    "abc = autoencoder.predict(figure)\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/OCR_summer/OCR_Dataset') \n",
    "cv2.imwrite('web_Cleaned_IMG_0845.JPG',abc[0]*255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
